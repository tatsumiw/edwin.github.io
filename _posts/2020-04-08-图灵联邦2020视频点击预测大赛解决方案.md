---
title: "图灵联邦2019视频点击预测大赛解决方案"
subtitle: "决赛答辩"
layout: post
author: "Tatsumi"
header-style: text
tags:
  - Match DataMining
---

```
一、模型创建思路
1. 赛题分析	本次比赛提供了大量视频投放数据，通过让参赛者构建预测模型来预估视频是否会被点击。很明显，这是一道关于CTR的问题。	解决此类问题主要有2个方向：    A. 构造小型推荐系统（老客）通过用户在站内的历史行为（包括曝光、点击、停留时长等信息确定用户感兴趣的视频信息，如果用户偏好与视频信息相匹配，则用户有更大几率点击视频）；    B. 构造冷启动模型（新客）。相比于老客有丰富的行为数据，在比赛提供的3天数据集中有部分用户缺少行为信息。对此我们需通过对视频端进行分析，确定受欢迎、热度高的视频候选集，候选集的视频对用户有更大的吸引力；           考虑以上2部分，我们需要充分挖掘用户维度和视频维度的信息，构造相应有效特征提高模型的准确率。
2. 探索性数据分析	由于本次比赛提供了数量达到千万级的数据，因此很有必要对部分数据样本和特征样本进行分析，以观察数据的分布情况。1) 对于训练数据集， deviceid没有缺失值，去重后共有104736个数据；而guid缺失了38204个数据，去重后共有104332个数据；    对于测试数据集，能与训练集关联的deviceid数为46833，而不能关联的达到57903，说明测试数据存在冷启动问    题。
2) 对视频的曝光时间戳进行解码后，我们发现训练集的日数是7，8，9，10号，而测试集的日数是10，11号。证明数据具有时序型，需要根据7，8，9，10号的用户点击行为来预测10，11号的点击趋势。
3) 统计不同时间段的曝光量，点击量和点击率变化，如图1，2所示。可以看出，相比起其他时间段，虽然半夜时分的曝光量和点击量都是最小的，但点击率较高，部分超过了0.12。                                                                             图 1  不同时间段的曝光量和点击量                                                                                 图 2  不同时间段的点击率
4) 统计视频推荐位置的曝光量，点击量和点击率情况，如图3，4所示。和统计时间段的情况类似，6，7，8这三个推荐位置的曝光量，点击量都低于其他位置，但其点击率却明显较高，甚至接近0.5。    另外，从位置0到8，点击率总体上都呈现单调递增的态势，说明视频推荐位置和用户点击行为可能有较强的相关性。                                                                       图 3  不同推荐位置的曝光量和点击量                                                                          图 4  不同推荐位置的点击率

5) 对于user表的用户维度的信息，统计各个特征、用户画像和标签的缺失值情况，如图5所示。明显看到除了deviceid，其他信息的缺失都较为严重，尤其是用户画像信息。这对用户的喜好属性与视频类别之间的关联处理有较大的影响。                                                                 图 5  user表特征、用户画像和标签的缺失值统计

6) 对于app表，统计每个存在的app对应的设备id数，如图6所示。序号为133和1的app对应的设备数是最多的。说明这两个是常用的app。                                                                                 图 6  每个app对应的设备id数（只显示部分数据）
3. 数据预处理	由于数据的噪声较多，且部分特征的缺失值较大，因此有必要对其进行一定的预处理，从而使模型更具鲁棒性，提高其泛化能力。对此，我们主要对少数时间边缘数据和地理位置数据进行调整和优化，删除异常值，并填充缺失值，对不同类型的数据填充不同类型的值。
4. 特征构建1) 对于训练集，每个视频在不同情况下是否被点击过都是已知的。这就意味着我们可以根据用户的历史点击行为来预测其未来的点击趋势。因此，我们构建了不同条件下视频的曝光量、点击量和点击率，挖掘历史点击信息。
2) 假设有一个视频A曝光给了一个用户，而这个用户对视频内容很感兴趣，那他就有可能点击这个视频A并观看一段时间。当他看完后又弹出了一个视频B，那么计算视频B与视频A的曝光时间差就在一定程度上表明用户可能点击过视频A。当然，也有可能是用户对视频A没有兴趣，但中途有其他事情做，而没有让视频B弹出，致使A，B的时间差较大。因此，可分别计算在不同情况下当前到前几次的视频曝光时间差，通过综合分析不同次数的时间差长短可知哪些视频具有潜在被点击的可能。
3) 单个特征与视频点击行为的相关性可能不大，但将两个特征进行交叉组合后可能会与标签产生一定关系。另外，构建二阶交叉特征也可能有一定的现实意义。比如计算某用户和某视频的共现次数与该用户出现次数的比例，从而获知用户是否偏爱该视频。因此，我们构建了一些二阶组合特征。
4) 在原始特征中，deviceid、newsid、lng_lat（由经纬度特征组合而成）等离散类别特征分别与结果的相关性都较大，在3）的启发下，可知用这些特征组合起来可能获得更强的特征。但这些类别特征所包含的总类别数可达十万量级，组合之后的新离散特征空间过大且过于稀疏，因此可以借助embedding的方法更有效地获取特征之间的关系，并进行降维。
5) 在用户APP安装列表往往隐藏用户的偏好信息，譬如音乐爱好者会安装各种音乐播放软件、而美妆爱好者会安装美图软件和购物软件。通过APP信息embedding化可一定程度上量化用户的偏好信息。
6) 通过对数据的分析发现基于pos、netmodel、lng和lat特征可以构造出用户的BATCH信息。所谓BATCH信息是每次用户有曝光行为时程序会向服务器请求数据，服务器每次返回的多条数据可认为是同个BATCH。而在同个BATCH中我们认为里面的是视频有着较高的相似度。通过计算BATCH的点击、曝光数据能更深刻挖掘视频的相关信息。
7) 对比用户点击数据发现，用户点击行为更偏向于连续行为，当点击某个视频后会有更大概率点击后一个视频、通过计算相邻视频netmodel、pos、ts差异能判断出在某时间序列中用户是否有频繁点击行为。
8) 在用户基础标签中Tag数据有丰富的用户偏好信息，通过用户与视频交互行为可把用户偏好映射至视频端汇总后作为视频端的描述信息、最后计算用户与视频端Tag标签的相似度，相似度越高，证明用户与该视频口味更吻合，更乐意点击。
5. 算法模型与训练方式1) 结合数据的时序性特点，利用Hand-Out验证方法进行线下验证，按照日期将训练集的数据划分为训练集和验证集。由于训练数据量较大，为了能加快训练速度，选择LightGBM模型来训练和验证数据，并对模型效果进行调整和优化。
2) 根据线下验证的调整进行线上测试。再次利用LightGBM模型重新整个训练集的数据，并预估测试集投放的视频是否会被点击。

二、模型说明
1. 数据预处理1) 虽然训练集有7号的数据，测试集有10号的数据，但相比起其他天数，这两天的数据都非常的少。而且这些数据的曝光时间戳都集中在23时59分59秒，非常接近8号和11号的零点，具有承接性。因此，为了之后方便对数据进行挖掘，将这极小数部分的数据的天数直接划分到8号和11号。
2) 我们将点击过的样本数据抽取出来后发现，有小部分数据的曝光时间戳比点击时间戳还大，这是不符合实际情况的，属于数据噪声。因此，去掉这些有问题的样本数据。
3) 直接将经纬度数据拼接在一起，获得一个具体的地理位置，将其当作一个新的类别特征进行处理。
4) 由于guid这个特征在train表和user表的缺失值较多，因此将其删去，并将deviceid作为user表, app表与train, test表拼接的连接键。
2. 特征工程1) 将train表和test表拼接后，对类别特征进行编码，并统计每个类别出现的次数，方便之后的特征构造和模型训练。
2) 根据数据分析和LightGBM模型对原始特征进行训练而得出的特征重要性分析，我们统计部分原始特征及其组合特征前一天的视频点击量、曝光量和点击率，挖掘历史点击信息。同时，在计算点击率时，为了防止位于分母的曝光量等于0，我们增加贝叶斯平滑。    另外，由于没有7号的数据，因此8号的历史点击特征为空值。这会对模型训练产生一定的影响。
3) 统计包括deviceid在内的部分原始特征及其组合特征当前到前几次（分别是1，2，3，5，10次）的视频曝光时间差。    相反地，构建穿越特征，即分别计算这些特征后几次（分别是1，2，3，5，10次）到当前的视频曝光时间差，以获取视频在未来被点击的信息，从而有效提高模型准确率。
4) 构建部分原始类别特征的二阶交叉特征。包括：类别变量的nuique、熵、组合特征的共现次数，比例偏好特征（组合特征的共现次数与其中一个类别的出现次数）。
5) embedding的思路如下：将deviceid、newsid、lng_lat等特征两两排列（先后顺序有区别），首先对前者按其下类别分组，然后每个分组下按时间顺序对后者提取词组成句子向量（sentence）以表征在前者某个类别下后者呈现的分布。显然这样得到的每个句子向量长度不一，便需要利用WordtoVec工具将其embedding到维度大小统一的新向量空间。在我们的实验中，采用的embedding空间维度大小为8。
6) 使用Word2Vec处理用户APP数据，对APP数据按照用户维度进行清洗和整合，根据对应的数值顺序进行排序（猜测该数据顺序有一定含义）使用CBOW训练词向量作为描述用户端的基础数据。
7) 构造Batch特征，用户在同一个netmodel、lng、lat下pos从小到大进行排序，每一个完整的pos序列认为是一个Batch。在此基础上计算每个Batch的统计特征（曝光时间差、曝光视频数、点击视频数）。
8) 考虑到用户点击行为有强烈的连续性，分别计算用户前（5、10、15、20）次曝光的点击量和点击率，pos位置差，最近、最远点击时间差，是否曾点击视频等统计特征，增加模型维度，提升模型最终效果。
9) 以打分的用户画像标签通过用户与视频的曝光关系，把用户标签映射至视频上，汇总视频标签的总得分作为视频的近似画像标签。计算视频端与用户端画像标签交集的总得分并归一化作为视频与用户的匹配度，充分使用已有数据。
3. 算法模型和训练方式1) 首先进行线下验证，按照日期将训练集的数据划分为训练集和验证集。其中训练集包含8，9号的数据，验证集包含10号的数据。再用LightGBM算法模型进行训练，其中部分参数设置为： 	Learning_rate = 0.01,	n_estimators=5000,	num_leaves=255,	subsample=0.9,	early_stopping_rounds=200.    并保留训练的迭代次数best_iteration。
2) 进行线上测试，即将8，9，10号的数据作为训练集，再次利用LightGBM模型重新训练数据，并预估11号投放的视频是否会被点击。其中将线下验证保留的迭代次数代入此模型的n_estimator中，确保线下线上的训练迭代次数大致相近，其他参数设置与线下验证的基本一致。    另外，训练结束后保存特征重要性的信息，以便分析所构建的特征是否有效，从而为之后的再特征构建提供帮助和参考。
3) 由于f1阈值较为敏感，有必要对其做一个搜索迭代，即给定一阈值初值，根据这一阈值对线下验证集的结果概率值进行分类，并计算验证集的f1分数。通过不断迭代获取最高的f1分数，并将其作为测试集的f1阈值。

三、相关经验技巧总结1. 对于其他类似的比赛，应留意所提供的原始特征中是否包含与时间相关的特征。若有，则思考是否可以构建穿越特征来提前获知未来的样本信息。这样可以提高模型的分类效果，使模型的泛化能力更好。
2. 计算某视频对应的点击率时，应考虑其历史性，即只能计算该视频曝光前点击率（历史点击率），而不能把曝光后的点击信息也纳入计算范围。否则容易造成模型的过拟合。
3. 由于本次比赛提供了大量数据，且需要构建上百个新的特征，因此在每次重新训练时都把整个代码跑一遍是十分耗时的，尤其是构建特征的过程。当了解哪些特征对分类结果有贡献后，可将这些预先构建好的特征保存下来。下次要用到时再将其合并到数据集中，与其他新构建的特征一起训练模型，从而大大提高建模效率。 
四、团队介绍
队长：陈东文个人简介：一枚来自华南理工大学的研二学生。虽然还只是个数据挖掘小白，但对大数据，人工智能等数据科学前沿知识具有浓厚兴趣。
队员：温文豪个人简介：广东工业大学大六学生，在某小型互联网公司搬小砖块，希望有机会跟各位大佬多多交流嗒。
队员：李振豪个人简介：华南理工大学研二学生，入门码农，希望跟大家多学些知识。
五、心路历程	虽然之前我们也参加过类似的数据挖掘比赛，但由于没有这方面的经验，一开始基本上都是四处碰壁，构建的大多数特征都不能有效地提分。之后经过不断查资料和研读冠军方案的博文和代码后，才慢慢地掌握了数据挖掘的整个流程，摸清了门路。   	刚参加这个比赛时，我们也是不知所措。与其他数据挖掘的比赛不同的是，这次比赛提供的数据量异常的大，达到千万级。幸好我们所在实验室的服务器内存能够扛得住，我们才没有轻易放弃比赛。不过在整个比赛的过程中，我们都受到了因数据量庞大而带来的烦恼，尤其是每次训练模型都得至少花了个一天的时间，有时因为服务器硬件出现问题或者代码最后才出现bug，导致要两三天才能跑完一个模型。所以我们总结了两个经验：一是若第一次跑代码，并且之后的模型需要用到此次模型构建的特征，那么当此次代码构建完新特征后，应该将其保存下来，以便之后可以直接拿来使用；二是在完整跑一次代码前可先运行部分代码，这样就不至于代码跑到最后才发现某处出现bug，耗费了大量时间。	整个比赛中，我们花费最多时间和精力的地方就在特征构建上。经过了两个月的思维锻炼和编写代码，我们逐渐领悟了在CTR任务中，构建新特征的策略和技巧，怎样用代码将各种想法实现起来。	经过这次比赛，我们都学到了很多数据挖掘领域里的知识，思维和技巧。最终决赛能拿到什么名次并不重要，关键是能从中学到有用的东西，总结出属于自己的方法论！
```


